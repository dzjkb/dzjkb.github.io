## experiments
idk man I can't do like proper searches for all of this shit
gotta follow the intuition
try running graz with
- slightly different weight settings
    - more for reconstruction?
- batch size 4

fuck, 800 epochs would be ~200pln, I can't afford that
0.25pln per epoch => 0.07 cents yeah that makes sense

ok ok fuck why don't I just train/tune on smaller datasets dude that's obvious wwsbgagbdf

snares? or a subset of graz, or a smaller piano one
- [x] what specs - training time, GPUs, etc. - did [[RAVE]] use?