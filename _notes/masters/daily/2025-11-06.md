## goals
pretty clear, tasks are listed in [[what do (masters)]] - on hold right now
next step would be metrics
## discriminators fr
gan loss term
backward - do I really need to do a [custom step](https://lightning.ai/docs/pytorch/stable/model/build_model_advanced.html) instead of relying on Lightning?

ok all these losses are getting confusing
**discriminator**:
- disc_loss - for each discriminator maximizing output on fakes and minimizing on reals
**generator**:
- feature matching loss - L1 between discriminator feature maps for real samples + their reconstruction
- spectral distance
- latent loss
- adversarial loss

- [x] what should the default weights be for these?
    - [[RVQGAN]] does `2.0` for features, `1.0` for adversarial and `15.0` for spectral distance????
    - [[RAVE]] does
```
_default_loss_weights = {
    'audio_distance': 1.,
    'multiband_audio_distance': 1.,
    'adversarial': 1.,
    'feature_matching' : 20,
}
```
the fuc
`v2.gin` does 10 but then `v3.gin` goes to 20 again

ok so [[RAVE]] runs the discriminator on concatenated real/fakes and then splits each feature map - looks like an optimization, batching the two together - can I actually do without this? will it slow down the whole thing considerably?
- it's run each training step, that's a lot

shit why does it skip n _first_ features not last - is the last critic output part of both the feature matching loss and the adversarial loss?????
- doesn't make sense try without but keep this in mind

ok warming up now
detach z after warmup epochs
ok it's not a warmup it's a fucking encoder training phase bro

ok runninggggggggggggggggggggggg
what now???
## huh?
- snake
- metrics - FAD?
    - who uses that again? maybe we can do without?
    - shit I'm not sure we have any other quality metric other than MOS though
    - MOS - specific algorithms?
- pqmf? is that necessary in our not-realtime several seconds usecase?
- normalizing flows
- reproducing RAVE/Melgan
    - should probably have a way to compare the results first - diversity, FAD? sth idk
    - I'm not even hoping to have higher quality, just comparable, no?
    - or I should compare with RAVE that compresses to a single latent (that's configurable right?)

oh shit wait `v3` also adds `AdaptiveInstanceNormalization` - what? why?
but it looks like [[RVQGAN]] doesn't
## augmentations
see [[VAE architecture]]
but `v3` seems to add no more augs than the defaults
out of these - maybe I could add randomm pitch and dequantization?
lots of ablation studies to do...

ok added phase mangling and dequantization
pitch maybe some day, gotta type this shit first
## adaptive instance normalization
introduced in [Arbitrary Style Transfer in Real-time with Adaptive Instance Normalization](https://arxiv.org/abs/1703.06868)
[official implementation](https://github.com/xunhuang1995/AdaIN-style)
[unofficial impl 1](https://github.com/CellEight/Pytorch-Adaptive-Instance-Normalization), [unofficial impl 2](https://github.com/naoto0804/pytorch-AdaIN)

what is this?
a layer
...