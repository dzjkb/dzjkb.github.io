## experiments
ok ok it's starting to look good on graz
validation loss going down to ~5, training loss decreasing below 4, latent loss slowly starting to increase after stabilizing
run for 1k more epochs?

ok I need to modify the timestamping for log directories to add to existing logging dirs when doing continuation runs
- add version number arg - would need to read from checkpoint path/state?
- remove timestamp
- [x] make continuation runs log to the same directory as the original run

ok losses still going down nicely, slowing down though, not sure when ~3 will be reached might be a while
- the "nice" runs reached ~3.6 validation reconstruction loss and ~3.0 train reconstruction loss
- while we're flattening out at ~4.8 goddammit, train at ~3.6
examples are starting to have a piano sound, very noisy though but still

**next**
try less initial latent loss - 1e-6, as previously
and maybe slightly more capacity?

or maybe continue this run with less latent loss?