## goals
pretty clear, tasks are listed in [[what do (masters)]] - on hold right now
next step would be metrics
## discriminators fr
these **feature losses** tf
- ok it's basically taking an intermediate layer of the discriminator ran on both _fake_ and _real_ data
- and adding `features_fake - features_real` as an additional term to the loss
what features does [[RAVE]] (or [[RVQGAN]] actually) take?
- looks like literally every layer activations are taken (after activation f)
- except the last conv which is a single channel result - "critic" output? but it's not 1x1 (or is it?)

**understanding MSD, MRD, MRSD**
MSD isn't actually used wops
MRD, MRSD described in [[VAE architecture]]

**loss step**
the `hinge_gan` loss is then calculated on the last elements of each feature map, so the values of the final convolutions, suggesting they're supposed to be the critic

other features are just mean-differenced

and that's it?
## snake activation
alpha is learned okkkkkkkkkkkkkkkkkkkkkkkk nice
looks like y=x but squiggly btw