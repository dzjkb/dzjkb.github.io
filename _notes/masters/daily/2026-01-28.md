mmm
## dataset
https://xethub.com/
downloading [[LAION-audio-630K]] - later browse, filter, process
messaged the [[Crash]] guy asking for the ds

in the meantime, add the downloaded things to `snares2`
- in `uni/mgr/sample_packs` or `/media/Data/jp_dir`
    - FSDKaggle2018, random reddit stuff
- or call it `percussive1`
 
process [FSD50K](https://zenodo.org/records/4060432)
- https://arxiv.org/abs/2010.00475
- 25GB, download to the drive - or to `gpu2:/media/Data`??
#### percussive1
ok creating percussive1, comprised of:
- snares1 train+val
- FSDKaggle2018 stuff, see [[datasets]] + the exploration notebook
    - which labels?
    - fuck ~~most of them were unverified~~ only 3.7k out of 9.5k samples are verified => possibly random stuff in the data
    - but also the 1.6k test samples are all verified
    - also loops, need to filter out those
    - and I'm left with 1103 samples from `"Hi-hat", "Bass_drum", "Snare_drum", "Gong", "Tambourine", "Cowbell"`
    - some are still loops, but it's aight
- other samples from the DLed sample packs
    - in `/media/Data/jp_dir/sounds/sample_packs`, unzip => move
- FSD50K?
why am I doing percussive anyway?
for "comparison", right
#### further ds stuff
try `soft_channel` but split the train/val sets into 90/10 sets and combine into new train/val to eliminate the out of distribution problem for different album tracks
- might be too easy then? but that's good, fuck it
- `soft_channel_2`
- running experiment

something with sfx? cmon