## experiments
ok something's not right
seems to be overfitting - ran for 1000 epochs, 400 was the lowest validation reconstruction loss
the previous runs (pre-PQMF) had a nice synchronous decrease of train and val losses
the model got smaller though?
- but the problem got easier maybe?
- same parameters as v3 [[RAVE]] though
- but the dataset is considerably smaller
- previous run had a very similar story

ok try decreasing the model size?
~6M parameters goddamn
but who knows maybe it might do something
ok it already beat the previous run at epoch 400, 700 epochs in it's 5.0 vs 6.3 previous validation loss

but previously the validation loss dropped to 4 at already 100 epochs (10h training, but this should't matter)

shit running the adversarial phase with a different batch size could make sense
if I just adjust lr's etc. appropriately
treat phase 1 as a base and then start fine-tuning experiments
would just need to get some reasonable performance out of phase 1 first