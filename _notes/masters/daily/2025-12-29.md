ok ok ok ok
## experiments
ok shapes why recap:
```
and why tf does the flow return `x: torch.Size([4, 2048, 2048])`????
nooooooooo
```
maybe I need to learn how this masked affine flow works first of all

and maybe I should verify these 2048 -> 16 -> 2048 MLPs can learn the complex distributions first of all?
with the `normflows` [RealNVP colab notebook](https://colab.research.google.com/github/VincentStimper/normalizing-flows/blob/master/examples/real_nvp_colab.ipynb) perhaps?
- nvm the example distributions are 2D, modifying this to create some random 2048 dimensional target distributions would be too much work
ok idk the vae.py example does this compression 40 -> 8 -> 40

ok idk it kind of fixed itself at some point oops
ok running `graz_full_mono_v0.yaml`
61s per epoch => 169h for 10k epochs => a week goddamn, well
shit need to freeze posterior too
- okdone
run veryfing a couple of thnigs:
- posterior flow training
- prior flow training
- discriminator training + warmup
- single latent vector
## normalizing flows
ok learn [[Real NVP]]
https://openreview.net/forum?id=HkpbnH9lx
https://arxiv.org/abs/1605.08803

ok got em