## experiments
oh wow peripeteia is actually learning something
maybe it will actually work after the discriminator phase?
need to run the encoder training for a while longer, maybe after the trip

meanwhile, `percussive1`
running oh boy
ok there's still this plateau at 11 wtf is wrong man
doing 128 latent dims
still plateauing around 10, maybe it'll jump like peripeteia did
- 40 dims under the free bits limit ~= 34%, not a good sign
- or is it? might fix itself with the latent weight increasing?
- grad norm hitting 100 constantly, maybe the limit is too small? trying 300, this might depend on `batch_size`, this might also keep it in local minima
- I swear to god it's happening again
- grads hitting 300, dims under 0.5 bits increasing
- maybe it's something in the `snares` data??? idk
## datasets
move stuff from `sample_packs` to `percussive1`
90/10 split, then go
batch size 6 ok ok safe safe
#### voice
any chance I can extract single words from [[VCTK]]? some kind of transcription processing?
- aligning text with sound sounds like a relatively easy problem
- "Forced alignment" according to this [huggingface thread](https://discuss.huggingface.co/t/text-to-speech-alignment-with-transformers/16166) (which suggests searching [github topics for forced alignment](https://github.com/topics/forced-alignment))
- ready tools lessssssgo - [aeneas](https://github.com/readbeyond/aeneas)
    - ok this one is from 2017 hm
- this one seems more recent - [Montreal-Forced-Aligner](https://github.com/MontrealCorpusTools/Montreal-Forced-Aligner)
    - [random blogpost comparing methods](https://memcauliffe.com/update-on-montreal-forced-aligner-performance.html), might come in handy to tune this
- ok of course Qwen3 does it too
    - [announcement article](https://howaiworks.ai/blog/qwen3-asr-announcement) literally posted today wow
    - [Qwen3-ForcedAligner-0.6B on huggingface](https://huggingface.co/Qwen/Qwen3-ForcedAligner-0.6B)
    - `qwen3-asr` pypi package, goddamn
    - this should be more than enough
#### thoughts
reporting results:
- percussive sounds
- voice would be great
- SFX or other novel interesting datasets
sidenote: researching ways to work on stereo audio would also be an interesting contribution, I guess looking at stereo doesn't make sense if you're not looking from a strictly music production perspective
## next
ok ok
- reproduce [[RAVE]]
- prepare the voice dataset
- sfx dataset
- read about [[CALM]] / Mimi
    - VAE + transformer combinations oh boy
## misc
[top audio/speech](https://github.com/01Zhangbw/Speech-and-audio-papers-Top-Conference) papers from the top conferences