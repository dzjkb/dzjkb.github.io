signed eu petition 12768267-8d32-4400-9448-18f4f06c361a
## experiments
tf is wrong man
find single latent VAE references -> images
- oh my https://github.com/PKU-YuanGroup/WF-VAE

try deeper arch - less parameters because of the bigger downsampling factor
- ok still overfitting fuckin hell man
- but the validation examples don't sound bad at all? just the metallic bitcrushed sound
seems reducing model size makes the loss generally higher but it doesn't make the validation loss fall instead of rising
- trying 16 capacity, still seems to be able to fit to the training data huh let's see
- also try more capacity but less latent dimensions - fkin 32 only
even more regularization??
running more regularization and 32 latent dims
- I swear to got it's the same fucking thing, a flat line after 300 epochs at around 19.5 what is your problem man
going extreme, 8 latent dims
- it's learning the training data similarly well to 32 dims you gotta be kidding me
- and the validation loss is actually decreasing???
- but from 22 to 20 in the span of 500 epochs....
- still, seems like the way forward?
- higher kld weight
- ok the val loss jumped at epoch 600, aborting

ok I don't understand, the validation reconstruction loss is super high, but the quality of the samples is pretty good
most of them have clear characteristics of the target sound - bassy toms or tight rims, just with static noise on top

ok idk go back to 32 latent dims with this high kld weight
same shit man validation loss at around 20 falling a bit then rising after 400 epochs
let the training go and see what's the unconditional generation going to look like?
- right the `last.ckpt` checkpoints are every 100 epochs oops
- and then resuming screws up the latest validation audio somehow (maybe it's because it's overwriting an existing clip?)
## fixes
validation step - how do I preserve this state without overwriting the whole load/save methods?
add them as "buffers"?
- yeah I guess

adversarial loss goes down to 1e-4 for a brief moment after discriminator warmup that's sus af

shit there's also multiband distance as the reconstruction loss aaaaaaaaaaaaaaaaa
ok done
- doesn't seem to change much
## next
datasets
- the LAION things
- also whatever [[DrumGAN]] was trained on?
then, launching baselines on the datasets
- compare to [[RAVE]] and [[Crash]]? (or [[DrumGAN]]) not sure crash is open, def wouldn't reproduce it on my own
- need to figure out how to do 1s samples priors with RAVE
and then => formalizing the contributions of my sampler

LAION
- ok filtering this 700GB would be a nightmare, I don't really have the processing power for that
- search subsets like https://huggingface.co/datasets?sort=likes&search=laion+sound

oh shi oh shi
https://github.com/xavierfav/Freesound-data-set/tree/master
https://www.tpointtech.com/40-open-source-audio-datasets-for-ml
https://zenodo.org/records/2552860
- 10 GB that's a nice size
- <=300 examples of each class, not much