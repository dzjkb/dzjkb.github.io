## experiments
still ongoing, starting to sound quite good though - definitely better than without discriminator training

next - tuning adam parameters on a different batch size on a T4
I can increase batch size to 4, looks like a ~3x speedup, nice
7min epoch, ok more like 2-2.5x

`activation: snake` makes the model use 2x more memory???? wtf
not sure the parameters are registered properly, since the initial logs show the same number of params/model size
no wait the size does increase actually, but by very little, why tf does it use so much memory then
## aws
ok setup done eh?
now - what batch size?
15G memory, not that much more than the 1080ti, maybe I can fit in a batch size 3 lol
run an experiment to see what the speedup will be

**note:** needed to install torchcodec
aand ffmpeg - added to `environment.yaml`
## datasets
chopin scherzos
debussy preludes