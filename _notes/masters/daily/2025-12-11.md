## experiments
ok shit the run was better
starting from lower losses, nicer curves
but stopped at ~3.5 training loss ~4.5 val loss, still far from the previous best results
maybe running adversarial training on this already should be good enough?

ok added discriminator warmup phase
this seems like a great idea
kind of scared of just launching training again, feel like I need to think it through more at this point before throwing more money at it

what would be the most informative thing I can do now
run [[RAVE]] on graz and see if it actually learns a good model
## embeddings
ok add KID to validation?
- baseline - validation set (cache somehow)
- eval set
    - validation reproductions, or
    - random generations?
why not both?

or maybe I shouldn't be adding these to validation epochs if I want to use them as test metrics
just do an eval notebook for a given checkpoint - from the unconditional generation notebook
- and run the functions after training? not sure tensorboard has a place for these kinds of metrics
## next
tf
normalizing flows? (configurable ofc)
- theory - what would they help with exactly?
    - "structure" of the latent space
- how can I measure that?
    - quality of unconditional generation (or maybe even conditional?)
// kind of tough to get started with this if I'm not sure the previous things are closed
// what would be closed? having a KID/FAD eval suite
## sem prez
ideas
1. creative music AI perspective
2. normalizing flows + VAEs + music
3. evaluation methods - embeddings, FAD
4. modeling music in different domains