shiiiiiiiit what now

- [ ] watch that guys PhD thesis - [Separating Explicit and Implicit Control for Expressive Neural Audio Synthesis](https://www.youtube.com/watch?v=rDfq9bwS6jk)
    - 2,5h goddamn

food for thought - modeling spectrograms with the complex component
- probably doesn't work that well for continuous real-time audio, but then that's not what I'm going for either
## rave reproduction
preprocessing the ds gives 0 samples wtf guys
ok had to set `num_signals` to `72000` for some reason

running training
fast as fuck : o is that the decomposition??
the descriminator size is the same so
model size is smaller despite higher capacity (96), can't think of any other reason than decomposition for this

why does validation launch so late
I gotta do the same thing

fucking discrimination throws an OOM again
results after 1300 epochs on graz mini (2h) very much still shaped static, but what do you expect
reduce batch size /2 => increase steps x2 => see what happens

but then again, I know I can run it now
do first comparison experiment?
- same batch size
- same lr or sum shi
what sense does a comparison make if it's a clone so far lol
more like a sanity check my shit works
## decomposition
ok ok ok
`CachedPQMF`, `PQMF`
Pseudo Quadrature Mirror Filter
oh god
why tf does this use convolutions and have learnable parameters etc
- only `CachedPQMF` has, they're used for caching what?
lots of technical math stuff, highest level stuff used is filters from scipy which isn't that high level really
the different conventions would suggest this is copied (adapted? hehe) from somewhere
- maybe just some open PQMF implementations? if that's a known concept

look at the [[Multi-band MelGAN]] impl too for reference
no impl provided
no impl for durian which it's based on too
ok [[Parallel WaveGan]] has an impl and that [[Multi-band MelGAN]] 3rd party thingy
why are they so short compared to the [[RAVE]] one omg