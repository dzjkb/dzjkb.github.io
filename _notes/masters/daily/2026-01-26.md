## experiments
let it run a bit longer, recon loss hasn't crossed 8, very much posterior collapse
but, interestingly enough, latent dims under the free bits threshold never exceed 6, which means over 90% are constantly utilized (at least from a "variance perspective")
rip, just get going with the data, fuck them snares
and hope these improvements will help with future trainings
wait maybe NFs would help at this point though??

try running soft channel maybe though?
ok looks like it's overfitting again, can't really learn the timbre but it's nice washes of noise
with a tiny bit of harmonic sound punching through, nice : o
bigger model perhaps?
ok 1400 epochs in the validation reconstruction is staying pretty much the same
although there's _slightly_ more harmonic content, which is nice
but this data is way too hard, for sure
ok running 512 latent dimensions fuck it
- oh god that's a giant encoder
- 77M parameters vs 41.7M for the decoder
- this is gonna be so overfit jeez
- hm at what model size should I think about more sequence specific latent up/down-sampling?
- LSTMs perhaps? it's almost like I'm doing the RAVE prior...
- or - attention!?
## datasets
download [[LAION-audio-630K]]
browse, filter, process

in the meantime, add the downloaded things to `snares2`
- in `uni/mgr/sample_packs` or `/media/Data/jp_dir`
    - FSDKaggle2018, random reddit stuff
 
process [FSD50K](https://zenodo.org/records/4060432)